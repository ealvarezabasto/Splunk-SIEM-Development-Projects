# Splunk-ES-Personal

This file provides a comprehensive guide to ingest data in Splunk ES using the UI-based approach.

## 1. Ingest Data
### 1.1 access.log log file
**Data Type:** HTTP Access Logs | **Description:** Records data of requests processed by Web-Server such as 'canceling a subscription', 'purchasing a product', etc.

* Settings > Add Data
  
  ![image](https://github.com/user-attachments/assets/87c80793-f86a-4cc4-81d0-42581523411d)

* Here you'll find 3 options to choose from:
  
  * **Upload:** This option allows users to manually upload files from their local system into Splunk.
It is typically used for one-time data ingestion, such as importing log files or CSV files.
Users can specify the source type and index during the upload process.

  * **Monitor:** The Monitor option is used to continuously monitor files or directories for new data.
It is ideal for real-time data ingestion, such as log files that are constantly being written to.
Users can specify file paths or directories, and Splunk will automatically index new data as it appears.

  * **Forward:** The Forward option is used to send data from one Splunk instance to another, typically from a forwarder to an indexer. This is part of Splunk's distributed architecture, allowing for centralized data collection and indexing.
Forwarding can be configured to send data in real-time or batch mode, depending on the requirements.

  <img width="443" alt="image" src="https://github.com/user-attachments/assets/ad0a81f6-e22a-4c55-8572-960c05d3387e" />

* Select **Upload** > classify **Source Type<sup>1</sup>** as **access_combined<sup>2</sup>** > Splunk parser parses information appropiately based on specific sourcetype

  * <sup>1</sup>**Source Type:** mandatory Splunk field that tells Splunk what kind of data contains the file so that it can format the data intelligently during indexing. In Splunk, field extractions and regex are generally defined at the source types level. If source type of your log is incorrect, then it will not get parsed properly. Splunk comes with some built-in source types and it's associated regex for commong logs. Every sourcetype has a regex.
  * <sup>2</sup>**access_combined:** NCSA combined format HTTP web server logs (can be generated by apache or other web servers)

  
  <img width="953" alt="image" src="https://github.com/user-attachments/assets/2cdbc27b-f5ae-49da-acb1-625f49701d79" />

* Access.log data successfully uploaded
  
  <img width="943" alt="image" src="https://github.com/user-attachments/assets/55143c4f-7c24-400d-8ef3-1d3b237a3aa4" />

### 1.2 secure.log log file
**Data Type:** Linux Authentication Logs | **Description:** Authentication Success & Failure Related Messages such as 'OS loging to your server', 'how many attempts made by an attacker', etc.

* Add Data > Classify **Source Type<sup>1</sup>** as **linux_secure<sup>2</sup>** > Splunk parser parses information appropiately based on specific sourcetype

  * <sup>1</sup> **Source Type:** In Splunk, field extractions and regex are generally defined at the source types level. If source type of your log is incorrect, then it will not get parsed properly. Splunk comes with some built-in source types and it's associated regex for commong logs. Every sourcetype has a regex.
  * <sup>2</sup> **linux_secure:** format for the /var/log/secure file containing all security related messsaged on a Linux machine.

  <img width="954" alt="image" src="https://github.com/user-attachments/assets/7a0d9fd1-a556-432e-8b8f-75014bdfc0c9" />

* secure.log data successfully uploaded
  
* However, some data has not been parsed appropiately.
  ![image](https://github.com/user-attachments/assets/e3fd4bc5-f084-48ea-8b9c-c8a65c34ec79)

* To fix this parsing issue, download 'Splunk Add-on for Unix and LInux' by going to Apps > Find more apps

  ![image](https://github.com/user-attachments/assets/773f211f-adbf-4d96-89f4-65a035034350)

  * Entire secure.log file is entirely getting parsed thanks to the installation of the add-on app.
    
  <img width="942" alt="image" src="https://github.com/user-attachments/assets/57382911-656a-4015-870a-0d421456bbbe" />

## 2. Importing Data Incorrectly by selecting incorrect SourceType
### 2.1 access.log log file
**Data Type:** HTTP Access Logs | **Description:** Records data of requests processed by Web-Server such as 'canceling a subscription', 'purchasing a product', etc.

* Settings > Add Data

  ![image](https://github.com/user-attachments/assets/87c80793-f86a-4cc4-81d0-42581523411d)

* Select Source > Next
  
  ![image](https://github.com/user-attachments/assets/55c99dfd-56ed-4107-9f07-42cbe65a0b3e)

### 2.2 Creating a customized Source Type
* Prior to selecting a Source Type, go to Settings > Source types where we will create our own source type

  ![image](https://github.com/user-attachments/assets/09aebd7a-0f48-41ec-a18e-1690e285bea5)

* Select 'New Source Type'

  ![image](https://github.com/user-attachments/assets/08a942f1-568a-49bb-8415-636c2ebf2c77)

* Create 'Source Type'

  ![image](https://github.com/user-attachments/assets/d09b73cd-5d58-42df-8930-e687fa317fc9)

### 2.3 For ingested data, have its sourcetype be the one recently created

* Return to prior page where you were uploading access.log file and select source type recently created

  ![image](https://github.com/user-attachments/assets/484162dc-fad8-413f-b30f-dd911576d5f6)

* Create a new index 'demosourcetype' and click 'Review'

  ![image](https://github.com/user-attachments/assets/ea30924e-2129-48d6-90d2-29b95c80da8d)

* Since the right sourcetype was not selected, not all fields were extracted correctly.
  
* transform.conf does not have the correct regex. If you would've selected 'access-combined' as the source type for access.log, the transform.conf would have the correct regex specifically for this type of log.

  ![image](https://github.com/user-attachments/assets/199ddfa7-e1f0-4d20-a099-c9dfc8fa8e4b)


## 3. Analyze/visualize data recently ingested
### Requirements
* **SCOPE:** Compliance auditor requested to find certain attack vectors related to SSH Logins.

### 3.1 Find how many type of logins from every IPs.
![image](https://github.com/user-attachments/assets/02e36151-5504-4244-9d6a-58c1f0680276)

### 3.2 Find List of Countries from which the failed login attempts were made:
* SPL Command: iplocation
* SPL Command: source="secure.log" action=blocked | iplocation src
* Note: Field src showcases the ipaddress of where the attempt is being made from.

### 2.3 Create a visualization of countries in world map based on failed logins.
* SPL Command: source="secure.log" | iplocation src | geostats count by Country
* ![image](https://github.com/user-attachments/assets/ec115e91-9f27-4e21-876f-c7c2533675ef)
